{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Warehousing Lab 3\n",
    "Chinonso Williams Ubani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in c:\\users\\ubani\\anaconda3\\lib\\site-packages (2.9.5)\n"
     ]
    }
   ],
   "source": [
    "# Installing the psycopg2 library\n",
    "!pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the libraries\n",
    "import psycopg2\n",
    "from configparser import ConfigParser\n",
    "import psycopg2.extras as extras\n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before connecting we need to configure the database name and password in the config file manually. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the connection to PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Section postgresql not found in the database.ini file\n"
     ]
    }
   ],
   "source": [
    "def config(filename='database.ini', section='postgresql'):\n",
    "    # create a parser\n",
    "    parser = ConfigParser()\n",
    "    # read config file\n",
    "    parser.read(filename)\n",
    "\n",
    "    # get section, default to postgresql\n",
    "    db = {}\n",
    "    if parser.has_section(section):\n",
    "        params = parser.items(section)\n",
    "        for param in params:\n",
    "            db[param[0]] = param[1]\n",
    "    else:\n",
    "        raise Exception('Section {0} not found in the {1} file'.format(section, filename))\n",
    "\n",
    "    return db\n",
    "\n",
    "\n",
    "\"\"\" Connect to the PostgreSQL database server \"\"\"\n",
    "conn = None\n",
    "try:\n",
    "    # read connection parameters\n",
    "    params = config()\n",
    "\n",
    "    # connect to the PostgreSQL server\n",
    "    print('Connecting to the PostgreSQL database...')\n",
    "    conn = psycopg2.connect(**params)\n",
    "\n",
    "    # create a cursor\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # execute a statement\n",
    "    print('PostgreSQL database version:')\n",
    "    cur.execute('SELECT version()')\n",
    "\n",
    "    # display the PostgreSQL database server version\n",
    "    db_version = cur.fetchone()\n",
    "    print(db_version)\n",
    "\n",
    "    # close the communication with the PostgreSQL\n",
    "    cur.close()\n",
    "except (Exception, psycopg2.DatabaseError) as error:\n",
    "    print(f\"Error: {error}\")\n",
    "finally:\n",
    "    if conn is not None:\n",
    "        conn.close()\n",
    "        print('Database connection closed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Tables to populate data from the working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Section postgresql not found in the database.ini file\n"
     ]
    }
   ],
   "source": [
    "\"\"\" create tables in the PostgreSQL database\"\"\"\n",
    "commands = (\n",
    "    \"\"\"\n",
    "  CREATE TABLE product (\n",
    "  product_key integer NOT NULL,\n",
    "  description varchar(200) NOT NULL,\n",
    "  full_description varchar(200) NOT NULL,\n",
    "  SKU_number bigint NOT NULL,\n",
    "  package_size varchar(200) NOT NULL,\n",
    "  brand varchar(200) NOT NULL,\n",
    "  subcategory varchar(200) NOT NULL,\n",
    "  category varchar(200) NOT NULL,\n",
    "  department varchar(200) NOT NULL,\n",
    "  package_type varchar(200) NOT NULL,\n",
    "  diet_type varchar(200) NOT NULL,\n",
    "  weight varchar(200) NOT NULL,\n",
    "  weight_unit_of_measure varchar(200) NOT NULL,\n",
    "  units_per_retail_case integer NOT NULL,\n",
    "  units_per_shipping_case integer NOT NULL,\n",
    "  cases_per_pallet integer NOT NULL,\n",
    "  shelf_width_cm integer NOT NULL,\n",
    "  shelf_height_cm integer NOT NULL,\n",
    "  shelf_depth_cm integer NOT NULL,\n",
    "  CONSTRAINT product_key_pk PRIMARY KEY (product_key))\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "CREATE TABLE promotion (\n",
    "promotion_key integer NOT NULL,\n",
    "promotion_name varchar(200) NOT NULL,\n",
    "price_reduction_type varchar(200) NOT NULL,\n",
    "ad_type varchar(200) NOT NULL,\n",
    "display_type varchar(200) NOT  NULL,\n",
    "coupon_type varchar(200) NOT NULL,\n",
    "ad_media_type varchar(200) NOT NULL,\n",
    "display_provider varchar(200) NOT NULL,\n",
    "promo_cost integer NOT NULL,\n",
    "promo_begin_date timestamp NOT NULL,\n",
    "promo_end_date timestamp NOT NULL ,\n",
    "CONSTRAINT promotion_key_pk PRIMARY KEY (promotion_key))\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "\n",
    "CREATE TABLE store (\n",
    "store_key integer NOT NULL,\n",
    "name varchar(200) NOT NULL,\n",
    "store_number integer NOT NULL,\n",
    "store_street_address varchar(200) NOT NULL,\n",
    "city varchar(200) NOT NULL,\n",
    "store_county varchar(200) NOT NULL,\n",
    "store_state\tvarchar(200) NOT NULL,\n",
    "store_zip varchar(200) NOT NULL,\n",
    "sales_district varchar(200) NOT NULL,\n",
    "sales_region varchar(200) NOT NULL,\n",
    "store_manager varchar(200) NOT NULL,\n",
    "store_phone varchar(200) NOT NULL,\n",
    "store_FAX varchar(200) NOT NULL,\n",
    "floor_plan_type varchar(200)\tNOT NULL,\n",
    "photo_processing_type varchar(200) NOT NULL,\n",
    "finance_services_type varchar(200) NOT NULL,\n",
    "first_opened_date timestamp NOT NULL,\n",
    "last_remodel_date timestamp NOT NULL,\n",
    "store_sqft integer NOT NULL,\n",
    "grocery_sqft integer NOT NULL,\n",
    "frozen_sqft\tinteger NOT NULL,\n",
    "meat_sqft integer NOT NULL,\n",
    "CONSTRAINT store_key_pk PRIMARY KEY (store_key))\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    CREATE TABLE time (\n",
    "time_key integer NOT NULL,\n",
    "date timestamp NOT NULL,\n",
    "day_of_week varchar(200) NOT NULL,\n",
    "day_number_in_month integer\tNOT NULL,\n",
    "day_number_overall integer NOT NULL,\n",
    "week_number_in_year integer\tNOT NULL,\n",
    "week_number_overall integer\tNOT NULL,\n",
    "Month integer NOT NULL,\n",
    "quarter integer NOT NULL,\n",
    "fiscal_period varchar(200) NOT NULL,\n",
    "year integer NOT NULL,\n",
    "holiday_flag varchar(200) NOT NULL,\n",
    "CONSTRAINT time_key_pk PRIMARY KEY (time_key));\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "CREATE TABLE sales_facts (\n",
    "product_key integer NOT NULL,\n",
    "promotion_key integer NOT NULL,\n",
    "store_key integer NOT NULL,\n",
    "time_key integer NOT NULL,\n",
    "dollar_sales integer NOT NULL,\n",
    "unit_sales integer NOT NULL,\n",
    "dollar_cost\tinteger NOT NULL,\n",
    "customer_count integer NOT NULL,\n",
    "CONSTRAINT fk_product_key FOREIGN KEY(product_key) REFERENCES product(product_key),\n",
    "CONSTRAINT fk_promotion_key FOREIGN KEY(promotion_key) REFERENCES promotion(promotion_key),\n",
    "CONSTRAINT fk_store_key FOREIGN KEY(store_key) REFERENCES store(store_key),\n",
    "CONSTRAINT fk_time_key FOREIGN KEY(time_key) REFERENCES time(time_key))\n",
    "    \"\"\"\n",
    ")\n",
    "conn = None\n",
    "try:\n",
    "    # read the connection parameters\n",
    "    params = config()\n",
    "    # connect to the PostgreSQL server\n",
    "    conn = psycopg2.connect(**params)\n",
    "    cur = conn.cursor()\n",
    "    # create table one by one\n",
    "    for command in commands:\n",
    "        cur.execute(command)\n",
    "    # close communication with the PostgreSQL database server\n",
    "    cur.close()\n",
    "    # commit the changes\n",
    "    conn.commit()\n",
    "except (Exception, psycopg2.DatabaseError) as error:\n",
    "    print(error)\n",
    "finally:\n",
    "    if conn is not None:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a function to populate the tables from the csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_values(conn, df, table):\n",
    "    tuples = [tuple(x) for x in df.to_numpy()]\n",
    "\n",
    "    cols = ','.join(list(df.columns))\n",
    "    # SQL query to execute\n",
    "    q = \"SET datestyle = dmy;\"\n",
    "    query = \"INSERT INTO %s(%s) VALUES %%s\" % (table, cols)\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        cursor.execute(q)\n",
    "        extras.execute_values(cursor, query, tuples)\n",
    "        conn.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error: %s\" % error)\n",
    "        conn.rollback()\n",
    "        cursor.close()\n",
    "        return 1\n",
    "    print(\"the dataframe is inserted\")\n",
    "    cursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data from the CSVs to the pandas dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we are reading the data in pandas to manupulate and clean the date to easily populate in the PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'product.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16460\\1601204784.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mproducts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'product.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpromotions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'promotion.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mstores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'store.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtimes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'time.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msales_facts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'salesFact.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'product.csv'"
     ]
    }
   ],
   "source": [
    "products = pd.read_csv('product.csv')\n",
    "promotions = pd.read_csv('promotion.csv')\n",
    "stores = pd.read_csv('store.csv')\n",
    "times = pd.read_csv('time.csv')\n",
    "sales_facts = pd.read_csv('salesFact.csv')\n",
    "\n",
    "for  index, row in times.iterrows():\n",
    "    fix_month = datetime.fromordinal(datetime(1900, 1, 1).toordinal() + row['Month'] - 2).timetuple().tm_mon\n",
    "    times.at[index, 'Month'] = fix_month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we are writing the data to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(**params)\n",
    "execute_values(conn, products, 'product')\n",
    "execute_values(conn, promotions, 'promotion')\n",
    "execute_values(conn, stores, 'store')\n",
    "execute_values(conn, times, 'time')\n",
    "execute_values(conn, sales_facts, 'sales_facts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are answering the questions using SQL queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• How many sales did the company have?  \n",
    "\n",
    "• How many products did we sale in a store last month?\n",
    "\n",
    "• Which one of our stores have the highest amount of sells?\n",
    "\n",
    "• Which products are the most lucrative?\n",
    "\n",
    "• What was the most lucrative day, month, or year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Connect to the PostgreSQL database server \"\"\"\n",
    "conn = None\n",
    "try:\n",
    "    # read connection parameters\n",
    "    params = config()\n",
    "\n",
    "    # connect to the PostgreSQL server\n",
    "    print('Connecting to the PostgreSQL database...')\n",
    "    conn = psycopg2.connect(**params)\n",
    "\n",
    "    # create a cursor\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    print('Question 1: How many sales did the company have?')\n",
    "    sql1 = '''SELECT SUM(unit_sales) as unit_sales\n",
    "FROM sales_facts;'''\n",
    "    cur.execute(sql1)\n",
    "    for i in cur.fetchall():\n",
    "        print(i)\n",
    "    print('Question 2: How many products did we sale in a store last month?')\n",
    "    sql1 = '''\n",
    "SELECT SUM(unit_sales) as unit_sales\n",
    "FROM sales_facts\n",
    "where time_key in (SELECT time_key from time where date between '1995-12-01' and '1995-12-31')\n",
    "and store_key in (SELECT store_key from store where store_number = '10')'''\n",
    "    cur.execute(sql1)\n",
    "    for i in cur.fetchall():\n",
    "        print(i)\n",
    "\n",
    "    print('Question 3: Which one of our stores have the highest amount of sells?')\n",
    "    sql1 = '''SELECT s.store_number, sum(sf.dollar_sales) as total_sales\n",
    "FROM sales_facts sf\n",
    "JOIN store s ON s.store_key = sf.store_key\n",
    "GROUP BY s.store_key\n",
    "order by total_sales desc;'''\n",
    "    cur.execute(sql1)\n",
    "    for i in cur.fetchall():\n",
    "        print(i)\n",
    "    print('Question 4: Which products are the most lucrative?')\n",
    "    sql1 = '''SELECT product.description as product_name , sum(sales_facts.dollar_sales) - sum(sales_facts.dollar_cost) as profit\n",
    "FROM sales_facts\n",
    "JOIN product ON product.product_key = sales_facts.product_key\n",
    "GROUP BY product.description\n",
    "order by profit desc;\n",
    "'''\n",
    "    cur.execute(sql1)\n",
    "    for i in cur.fetchall():\n",
    "        print(i)\n",
    "    print('Question 5 : What was the most lucrative year?')\n",
    "    sql1 = '''SELECT time.year, sum(sales_facts.dollar_sales) - sum(sales_facts.dollar_cost) as profit\n",
    "FROM sales_facts\n",
    "JOIN time ON time.time_key = sales_facts.time_key\n",
    "GROUP BY time.year\n",
    "order by profit desc;'''\n",
    "    cur.execute(sql1)\n",
    "    for i in cur.fetchall():\n",
    "        print(i)\n",
    "    print('Question 5: What was the most lucrative day of the week?')\n",
    "    sql1 = '''SELECT time.day_of_week, sum(sales_facts.dollar_sales) - sum(sales_facts.dollar_cost) as profit\n",
    "FROM sales_facts\n",
    "JOIN time ON time.time_key = sales_facts.time_key\n",
    "GROUP BY time.day_of_week\n",
    "order by profit desc;'''\n",
    "    cur.execute(sql1)\n",
    "    for i in cur.fetchall():\n",
    "        print(i)\n",
    "    print('Question 5 : What was the most lucrative month?')\n",
    "    sql1 = '''SELECT time.month, sum(sales_facts.dollar_sales) - sum(sales_facts.dollar_cost) as profit\n",
    "FROM sales_facts\n",
    "JOIN time ON time.time_key = sales_facts.time_key\n",
    "GROUP BY time.month\n",
    "order by profit desc;'''\n",
    "    cur.execute(sql1)\n",
    "    for i in cur.fetchall():\n",
    "        print(i)\n",
    "    # close the communication with the PostgreSQL\n",
    "    cur.close()\n",
    "except (Exception, psycopg2.DatabaseError) as error:\n",
    "    print(f\"Error: {error}\")\n",
    "finally:\n",
    "    if conn is not None:\n",
    "        conn.close()\n",
    "        print('Database connection closed.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
